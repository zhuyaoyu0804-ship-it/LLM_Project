import streamlit as st
import pandas as pd
import os
from rag_engine import RAGManager
from utils import save_uploaded_file

import sys
# --- é¡µé¢é…ç½® ---
st.set_page_config(
    page_title="RAG çŸ¥è¯†åº“è°ƒè¯•å¹³å°",
    page_icon="ğŸ“š",
    layout="wide"
)

# --- æ ·å¼ ---
st.markdown("""
<style>
    /* éšè—é»˜è®¤çš„åˆ†å‰²çº¿å’Œè¾¹æ¡† */
    .stApp > header {
        background-color: transparent;
    }
    
    /* ä¸»å®¹å™¨æ ·å¼ */
    .main .block-container {
        padding: 2rem 3rem;
        max-width: 1400px;
    }
    
    /* å¡ç‰‡æ ·å¼ */
    .card {
        background: linear-gradient(145deg, #ffffff, #f5f7fa);
        border-radius: 16px;
        padding: 1.5rem;
        margin: 1rem 0;
        box-shadow: 0 4px 20px rgba(0, 0, 0, 0.08);
        border: 1px solid rgba(255, 255, 255, 0.8);
    }
    
    .card-header {
        font-size: 1.1rem;
        font-weight: 600;
        color: #1a1a2e;
        margin-bottom: 1rem;
        display: flex;
        align-items: center;
        gap: 0.5rem;
    }
    
    /* ä¾§è¾¹æ ç¾åŒ– */
    [data-testid="stSidebar"] {
        background: linear-gradient(180deg, #1a1a2e 0%, #16213e 100%);
    }
    
    [data-testid="stSidebar"] .stMarkdown h1,
    [data-testid="stSidebar"] .stMarkdown h2,
    [data-testid="stSidebar"] .stMarkdown h3 {
        color: #e8e8e8 !important;
    }
    
    [data-testid="stSidebar"] label {
        color: #b8b8b8 !important;
    }
    
    /* æŒ‰é’®ç¾åŒ– */
    .stButton > button {
        width: 100%;
        border-radius: 12px;
        font-weight: 600;
        transition: all 0.3s ease;
        border: none;
    }
    
    .stButton > button[kind="primary"] {
        background: linear-gradient(135deg, #667eea 0%, #764ba2 100%);
        color: white;
    }
    
    .stButton > button[kind="primary"]:hover {
        transform: translateY(-2px);
        box-shadow: 0 6px 20px rgba(102, 126, 234, 0.4);
    }
    
    .stButton > button[kind="secondary"] {
        background: linear-gradient(135deg, #ff6b6b 0%, #ee5a5a 100%);
        color: white;
    }
    
    /* è¾“å…¥æ¡†ç¾åŒ– */
    .stTextInput input, .stSelectbox select {
        border-radius: 10px !important;
        border: 2px solid #e0e0e0 !important;
    }
    
    .stTextInput input:focus {
        border-color: #667eea !important;
        box-shadow: 0 0 0 3px rgba(102, 126, 234, 0.2) !important;
    }
    
    /* æ ‡ç­¾é¡µç¾åŒ– */
    .stTabs [data-baseweb="tab-list"] {
        gap: 8px;
        background-color: #f5f7fa;
        padding: 0.5rem;
        border-radius: 12px;
    }
    
    .stTabs [data-baseweb="tab"] {
        border-radius: 8px;
        padding: 0.5rem 1.5rem;
        font-weight: 500;
    }
    
    .stTabs [aria-selected="true"] {
        background: linear-gradient(135deg, #667eea 0%, #764ba2 100%);
        color: white !important;
    }
    
    /* Chunk é¢„è§ˆåŒºåŸŸ */
    .chunk-preview {
        background: #f8fafc;
        padding: 1rem;
        border-radius: 10px;
        font-family: 'JetBrains Mono', 'Consolas', monospace;
        font-size: 0.85rem;
        white-space: pre-wrap;
        border-left: 4px solid #667eea;
        max-height: 400px;
        overflow-y: auto;
    }
    
    /* æ–‡ä»¶åˆ—è¡¨é¡¹ */
    .file-item {
        display: flex;
        align-items: center;
        padding: 0.8rem 1rem;
        background: #ffffff;
        border-radius: 10px;
        margin: 0.5rem 0;
        box-shadow: 0 2px 8px rgba(0, 0, 0, 0.04);
        transition: all 0.2s ease;
    }
    
    .file-item:hover {
        transform: translateX(4px);
        box-shadow: 0 4px 12px rgba(0, 0, 0, 0.08);
    }
    
    /* èŠå¤©æ¶ˆæ¯ç¾åŒ– */
    [data-testid="stChatMessage"] {
        border-radius: 16px;
        margin: 0.5rem 0;
    }
    
    /* éšè—è°ƒè¯•ä¿¡æ¯ */
    .debug-info {
        display: none;
    }
    
    /* ç»Ÿè®¡æ•°å­—æ ‡ç­¾ */
    .stat-badge {
        background: linear-gradient(135deg, #667eea 0%, #764ba2 100%);
        color: white;
        padding: 0.25rem 0.75rem;
        border-radius: 20px;
        font-size: 0.8rem;
        font-weight: 600;
    }
</style>
""", unsafe_allow_html=True)

# --- åˆå§‹åŒ– Session State ---
if "rag" not in st.session_state:
    st.session_state.rag = RAGManager()

if "messages" not in st.session_state:
    st.session_state.messages = []

if "latest_chunks" not in st.session_state:
    st.session_state.latest_chunks = []

# --- ä¾§è¾¹æ  ---
with st.sidebar:
    st.title("âš™ï¸ é…ç½®é¢æ¿")
    
    st.header("1. æ–‡æ¡£ä¸Šä¼ ")
    uploaded_files = st.file_uploader(
        "é€‰æ‹©æ–‡æ¡£ (PDF, TXT, MD)", 
        accept_multiple_files=True,
        type=["pdf", "txt", "md"]
    )
    
    st.header("2. åˆ‡åˆ†å‚æ•°")
    split_method = st.selectbox(
        "åˆ‡åˆ†æ–¹å¼",
        options=["recursive", "fixed"],
        format_func=lambda x: "é€’å½’å­—ç¬¦åˆ‡åˆ† (æ¨è)" if x == "recursive" else "å›ºå®šå¤§å°åˆ‡åˆ†",
        index=0,
        help="é€’å½’åˆ‡åˆ†ä¼šæŒ‰æ®µè½ã€å¥å­æ™ºèƒ½åˆ†å‰²ï¼›å›ºå®šåˆ‡åˆ†åˆ™æŒ‰å­—ç¬¦æ•°ç¡¬åˆ‡"
    )
    chunk_size = st.number_input("Chunk Size (å­—ç¬¦æ•°)", min_value=50, max_value=4000, value=500, step=50)
    chunk_overlap = st.number_input("Chunk Overlap (é‡å å­—ç¬¦)", min_value=0, max_value=500, value=50, step=10)
    
    if st.button("ğŸ—ï¸ æ„å»º/è¿½åŠ çŸ¥è¯†åº“", type="primary"):
        if not uploaded_files:
            st.warning("è¯·å…ˆä¸Šä¼ æ–‡ä»¶ï¼")
        else:
            with st.spinner("æ­£åœ¨å¤„ç†æ–‡æ¡£..."):
                all_new_chunks = []
                temp_dir = "temp_uploads"
                for uploaded_file in uploaded_files:
                    # ä¿å­˜æ–‡ä»¶
                    file_path = save_uploaded_file(uploaded_file, temp_dir)
                    # å¤„ç† (ä¼ å…¥åˆ‡åˆ†æ–¹å¼)
                    chunks = st.session_state.rag.process_file(
                        file_path, 
                        chunk_size, 
                        chunk_overlap,
                        split_method=split_method
                    )
                    all_new_chunks.extend(chunks)
                
                st.session_state.latest_chunks = all_new_chunks
                st.success(f"æˆåŠŸå¤„ç† {len(uploaded_files)} ä¸ªæ–‡ä»¶ï¼Œå…±ç”Ÿæˆ {len(all_new_chunks)} ä¸ª Chunksï¼")
    
    st.header("3. LLM è®¾ç½® (é»˜è®¤æ™ºè°± AI)")
    
    # è‡ªåŠ¨æ£€æµ‹ç¯å¢ƒå˜é‡
    env_key = os.environ.get("ZHIPU_API_KEY", "")
    api_key_placeholder = "å·²æ£€æµ‹åˆ° ZHIPU_API_KEY" if env_key else "è¯·è¾“å…¥ API Key"
    
    api_key = st.text_input("API Key (ä¸ºç©ºåˆ™ä½¿ç”¨ ZHIPU_API_KEY)", type="password", placeholder=api_key_placeholder)
    base_url = st.text_input("Base URL", value="https://open.bigmodel.cn/api/paas/v4/")
    model_name = st.text_input("Model Name", value="glm-4-flash")

    st.divider()
    
    st.header("âš ï¸ å±é™©æ“ä½œ")
    if st.button("ğŸ—‘ï¸ æ¸…ç©ºæ‰€æœ‰çŸ¥è¯†åº“", type="secondary"):
        st.session_state.rag.clear_database()
        st.session_state.latest_chunks = []
        # å¼ºåˆ¶åˆ·æ–°ä»¥æ›´æ–°ç•Œé¢çŠ¶æ€
        st.success("çŸ¥è¯†åº“å·²æ¸…ç©ºï¼")
        st.rerun()

# --- ä¸»ç•Œé¢ ---
st.title("ğŸ“š VisRAG - å¯è§†åŒ– RAG è°ƒè¯•å¹³å°")

tab1, tab2 = st.tabs(["ğŸ“– çŸ¥è¯†åº“ç®¡ç† & é¢„è§ˆ", "ğŸ¤– RAG å¯¹è¯æµ‹è¯•"])

# === Tab 1: çŸ¥è¯†åº“ç®¡ç† ===
with tab1:
    # ä½¿ç”¨ä¸¤åˆ—å¸ƒå±€å¡«å……ç©ºé—´
    col_left, col_right = st.columns([1, 1])
    
    with col_left:
        st.markdown("""
        <div class="card">
            <div class="card-header">ğŸ“Š å·²åŠ è½½æ–‡æ¡£</div>
        </div>
        """, unsafe_allow_html=True)
        
        # è·å–å½“å‰æ•°æ®åº“çŠ¶æ€
        file_stats = st.session_state.rag.get_all_documents_metadata()
        
        if not file_stats:
            st.info("ğŸ“­ å½“å‰çŸ¥è¯†åº“ä¸ºç©ºã€‚è¯·åœ¨ä¾§è¾¹æ ä¸Šä¼ æ–‡æ¡£å¹¶ç‚¹å‡»æ„å»ºã€‚")
        else:
            # ç»Ÿè®¡ä¿¡æ¯
            total_chunks = sum(f['count'] for f in file_stats)
            st.markdown(f"""
            <div style="display: flex; gap: 1rem; margin-bottom: 1rem;">
                <div class="stat-badge">ğŸ“ {len(file_stats)} ä¸ªæ–‡ä»¶</div>
                <div class="stat-badge">ğŸ“„ {total_chunks} ä¸ª Chunks</div>
            </div>
            """, unsafe_allow_html=True)
            
            # æ˜¾ç¤ºæ–‡ä»¶åˆ—è¡¨
            for file_data in file_stats:
                with st.container():
                    col1, col2, col3 = st.columns([4, 2, 1])
                    with col1:
                        st.markdown(f"ğŸ“„ **{os.path.basename(file_data['source'])}**")
                    with col2:
                        st.caption(f"{file_data['count']} chunks")
                    with col3:
                        if st.button("ğŸ—‘ï¸", key=f"del_{file_data['source']}", help="åˆ é™¤æ­¤æ–‡ä»¶"):
                            st.session_state.rag.delete_document(file_data['source'])
                            st.toast(f"å·²åˆ é™¤ {os.path.basename(file_data['source'])}")
                            st.rerun()
    
    with col_right:
        st.markdown("""
        <div class="card">
            <div class="card-header">ğŸ” Chunk é¢„è§ˆ</div>
        </div>
        """, unsafe_allow_html=True)
        
        if st.session_state.latest_chunks:
            # è½¬æ¢ä¸º DataFrame ç”¨äºå±•ç¤º
            data = []
            for i, chunk in enumerate(st.session_state.latest_chunks):
                data.append({
                    "ID": i,
                    "æ¥æº": os.path.basename(chunk.metadata.get("source", "Unknown")),
                    "å­—ç¬¦æ•°": len(chunk.page_content),
                    "å†…å®¹é¢„è§ˆ": chunk.page_content[:100] + "..." if len(chunk.page_content) > 100 else chunk.page_content
                })
            
            df = pd.DataFrame(data)
            st.dataframe(df, use_container_width=True, height=300)
            
            # è¯¦æƒ…æŸ¥çœ‹
            st.markdown("---")
            selected_id = st.number_input("ğŸ”¢ è¾“å…¥ Chunk ID æŸ¥çœ‹å®Œæ•´å†…å®¹", min_value=0, max_value=len(data)-1, value=0, step=1)
            if 0 <= selected_id < len(data):
                with st.expander(f"ğŸ“ Chunk {selected_id} å®Œæ•´å†…å®¹", expanded=True):
                    st.markdown(f"<div class='chunk-preview'>{st.session_state.latest_chunks[selected_id].page_content}</div>", unsafe_allow_html=True)
                with st.expander("ğŸ·ï¸ å…ƒæ•°æ®"):
                    st.json(st.session_state.latest_chunks[selected_id].metadata)
        else:
            st.info("ğŸ’¡ æ„å»ºçŸ¥è¯†åº“åï¼Œè¿™é‡Œå°†æ˜¾ç¤ºåˆ‡åˆ†åçš„ Chunk é¢„è§ˆã€‚")
            st.markdown("""
            **ä½¿ç”¨è¯´æ˜**:
            1. åœ¨å·¦ä¾§ä¸Šä¼ æ–‡æ¡£
            2. é€‰æ‹©åˆ‡åˆ†æ–¹å¼å’Œå‚æ•°
            3. ç‚¹å‡»ã€Œæ„å»ºçŸ¥è¯†åº“ã€æŒ‰é’®
            """)

# === Tab 2: RAG å¯¹è¯ ===
with tab2:
    col_config, col_chat = st.columns([1, 3])
    
    with col_config:
        st.markdown("**ğŸ”§ æ£€ç´¢é…ç½®**")
        search_type = st.radio(
            "æ£€ç´¢æ¨¡å¼",
            ["Vector", "BM25", "Hybrid"],
            index=0,
            help="Vector: è¯­ä¹‰ç›¸ä¼¼åº¦ | BM25: å…³é”®å­—åŒ¹é… | Hybrid: ç»¼åˆæ’åº"
        )
        # ç›´æ¥ä½¿ç”¨é€‰æ‹©çš„å€¼
        real_search_type = search_type
            
    with col_chat:
        # æ˜¾ç¤ºå†å²æ¶ˆæ¯
        for msg in st.session_state.messages:
            with st.chat_message(msg["role"]):
                st.markdown(msg["content"])
                if "source_documents" in msg:
                    with st.expander("ğŸ” æ£€ç´¢åˆ°çš„ä¸Šä¸‹æ–‡ (å†å²è®°å½•)"):
                        for doc in msg["source_documents"]:
                            st.markdown(f"**æ¥æº**: `{os.path.basename(doc.metadata.get('source', 'unknown'))}`")
                            st.markdown(f"```\n{doc.page_content[:200]}...\n```")

        # è¾“å…¥æ¡†
        if prompt := st.chat_input("è¯·è¾“å…¥ä½ çš„é—®é¢˜..."):
            # 1. æ˜¾ç¤ºç”¨æˆ·è¾“å…¥
            st.session_state.messages.append({"role": "user", "content": prompt})
            with st.chat_message("user"):
                st.markdown(prompt)

            # 2. è°ƒç”¨ RAG
            # è¿™é‡Œçš„ check ç¨å¾®å®½å®¹ä¸€ç‚¹ï¼Œå¦‚æœæ²¡æœ‰è¾“å…¥ key ä½†æ˜¯æœ‰ env key ä¹Ÿå¯ä»¥
            final_key = api_key or os.environ.get("ZHIPU_API_KEY")
            
            if not final_key:
                st.error("è¯·åœ¨ä¾§è¾¹æ å¡«å†™ API Keyï¼Œæˆ–è®¾ç½® ZHIPU_API_KEY ç¯å¢ƒå˜é‡ï¼")
            else:
                with st.chat_message("assistant"):
                    with st.spinner("æ­£åœ¨æ€è€ƒ..."):
                        try:
                            result = st.session_state.rag.chat(
                                query=prompt,
                                api_key=api_key, # ä¼ å…¥åŸå§‹è¾“å…¥å³å¯ï¼Œrag_engine å†…éƒ¨ä¼šå†æ¬¡ fallback
                                base_url=base_url,
                                model_name=model_name,
                                search_type=real_search_type
                            )
                            
                            answer = result.get("answer")
                            source_docs = result.get("source_documents", [])
                            
                            # å±•ç¤ºæ£€ç´¢åˆ°çš„ä¸Šä¸‹æ–‡
                            with st.expander("ğŸ” æ£€ç´¢åˆ°çš„ä¸Šä¸‹æ–‡", expanded=True):
                                if not source_docs:
                                    st.write("æœªæ£€ç´¢åˆ°ç›¸å…³æ–‡æ¡£ã€‚")
                                for i, doc in enumerate(source_docs):
                                    st.markdown(f"**DOC {i+1}** - `{os.path.basename(doc.metadata.get('source', 'unknown'))}`")
                                    st.markdown(f"```\n{doc.page_content}...\n```")
                            
                            # å±•ç¤ºå›ç­”
                            st.markdown(answer)
                            
                            # ä¿å­˜å†å²
                            st.session_state.messages.append({
                                "role": "assistant", 
                                "content": answer,
                                "source_documents": source_docs
                            })
                            
                        except Exception as e:
                            st.error("æ‰§è¡Œå‡ºé”™ï¼Œè¯¦ç»†æ—¥å¿—è¯·æŸ¥çœ‹ç»ˆç«¯ã€‚")
                            st.exception(e)

